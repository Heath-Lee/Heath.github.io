<!DOCTYPE html>
<html>
	<body>
		<div class="wrap">
			<h1>Heesung heath Lee</h1>
			<p>이희승</p>
			<h2>自强不息 厚德載物</h2>
			<div class="content">
				<div class="hero">
					<img alt="how-to-paint-still-life-oils-cezanne.jpg" src="/Heath-Lee/heath-lee.github.io/blob/master/how-to-paint-still-life-oils-cezanne.jpg">
					<p>Our experiments show that Document Retriever outperforms the built-in Wikipedia search engine and that Document Reader reaches state-of-theart results on the very competitive SQuAD benchmark(Rajpurkaretal.,2016). Finally, our full system is evaluated using multiple benchmarks. We show that performance is improved across all datasets through the use of multitask learning and distant supervision compared to single task training. 
					<p>https://brunch.co.kr/@kakao-it/139
					<p>https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#pointer-network
					<p>https://dalpo0814.tistory.com/category/Machine%20Learning
					<p>https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjjmt2Q5rHgAhUN7WEKHYhFDyoQFjAAegQIYhAC&url=https%3A%2F%2Fesc.fnwi.uva.nl%2Fthesis%2Fcentraal%2Ffiles%2Ff319064750.pdf&usg=AOvVaw15E72SXy3cxsXBp7STU-RI
					<p>http://hugrypiggykim.com/2018/12/09/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding/
					<p>https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec
				</div>
			</div>
		</div>
	</body>
</html>
